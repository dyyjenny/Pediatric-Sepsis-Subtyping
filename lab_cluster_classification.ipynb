{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dtaidistance import dtw_ndim\n",
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as shc\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import seaborn as sns\n",
    "import pyreadr\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "# https://heartbeat.comet.ml/how-to-evaluate-clustering-based-models-in-python-503343816db2\n",
    "from sklearn.metrics import davies_bouldin_score, calinski_harabasz_score, silhouette_score\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate, RepeatedKFold, ShuffleSplit, RandomizedSearchCV, GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# meta_num = pd.read_csv('filename')\n",
    "labs = meta_num[['pco2','lact','ph_min','gluc_max',\n",
    "             'inr','ptt','d_dimer','plts',\n",
    "             'alt', 'ast','bili', 'creat', 'bun' ,\n",
    "             'wbc_max','bands','alc']]\n",
    "\n",
    "# make labels in to separate np array\n",
    "label_orig = np.array(meta_num['cluster_label_orig'].tolist())\n",
    "label_v2 = np.array(meta_num['cluster_label_v2'].tolist())\n",
    "label_pen2 = np.array(meta_num['cluster_label_pen2'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale each fature\n",
    "scaler = StandardScaler()\n",
    "labs_scaled = scaler.fit_transform(labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# comparing cross validation results on diff labels\n",
    "hgb = HistGradientBoostingClassifier()\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2)\n",
    "scores_hgb = cross_validate(hgb, labs_scaled, label_orig.ravel(), cv=cv, scoring=('accuracy','precision','recall','roc_auc'),return_train_score=True)\n",
    "\n",
    "hgb = HistGradientBoostingClassifier()\n",
    "scores_hgb_v2 = cross_validate(hgb, labs_scaled, label_v2.ravel(), cv=cv, scoring=('accuracy','precision','recall','roc_auc'),return_train_score=True)\n",
    "\n",
    "hgb = HistGradientBoostingClassifier()\n",
    "scores_hgb_pen2 = cross_validate(hgb, labs_scaled, label_pen2.ravel(), cv=cv, scoring=('accuracy','precision','recall','roc_auc'),return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy 0.7679500926016181\n",
      "train precision 0.7598408775308688\n",
      "train recall 0.9752093555021307\n",
      "train roc_auc 0.7975746912389609\n",
      "test accuracy 0.7122027290448344\n",
      "test precision 0.7249288128850352\n",
      "test recall 0.9436462791777384\n",
      "test roc_auc 0.6402245430891982\n"
     ]
    }
   ],
   "source": [
    "# print model output for original label\n",
    "print ('train accuracy', scores_hgb['train_accuracy'].mean())\n",
    "print ('train precision', scores_hgb['train_precision'].mean())\n",
    "print ('train recall', scores_hgb['train_recall'].mean())\n",
    "print ('train roc_auc', scores_hgb['train_roc_auc'].mean())\n",
    "print ('test accuracy', scores_hgb['test_accuracy'].mean())\n",
    "print ('test precision', scores_hgb['test_precision'].mean())\n",
    "print ('test recall', scores_hgb['test_recall'].mean())\n",
    "print ('test roc_auc', scores_hgb['test_roc_auc'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy 0.885290964031582\n",
      "train precision 0.8929145847218971\n",
      "train recall 0.15680969584395005\n",
      "train roc_auc 0.8466927171378584\n",
      "test accuracy 0.8707212475633529\n",
      "test precision 0.544733455259771\n",
      "test recall 0.06401160167846282\n",
      "test roc_auc 0.6790992404943975\n"
     ]
    }
   ],
   "source": [
    "# print model output for data v2 penalty = 5\n",
    "print ('train accuracy', scores_hgb_v2['train_accuracy'].mean())\n",
    "print ('train precision', scores_hgb_v2['train_precision'].mean())\n",
    "print ('train recall', scores_hgb_v2['train_recall'].mean())\n",
    "print ('train roc_auc', scores_hgb_v2['train_roc_auc'].mean())\n",
    "print ('test accuracy', scores_hgb_v2['test_accuracy'].mean())\n",
    "print ('test precision', scores_hgb_v2['test_precision'].mean())\n",
    "print ('test recall', scores_hgb_v2['test_recall'].mean())\n",
    "print ('test roc_auc', scores_hgb_v2['test_roc_auc'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy 0.8756603957500732\n",
      "train precision 0.9378429207796637\n",
      "train recall 0.10894872903187425\n",
      "train roc_auc 0.83471320523567\n",
      "test accuracy 0.8617543859649123\n",
      "test precision 0.43793795338786856\n",
      "test recall 0.034577294558604324\n",
      "test roc_auc 0.6616346161176383\n"
     ]
    }
   ],
   "source": [
    "# print model output for data v2 penalty = 2\n",
    "print ('train accuracy', scores_hgb_pen2['train_accuracy'].mean())\n",
    "print ('train precision', scores_hgb_pen2['train_precision'].mean())\n",
    "print ('train recall', scores_hgb_pen2['train_recall'].mean())\n",
    "print ('train roc_auc', scores_hgb_pen2['train_roc_auc'].mean())\n",
    "print ('test accuracy', scores_hgb_pen2['test_accuracy'].mean())\n",
    "print ('test precision', scores_hgb_pen2['test_precision'].mean())\n",
    "print ('test recall', scores_hgb_pen2['test_recall'].mean())\n",
    "print ('test roc_auc', scores_hgb_pen2['test_roc_auc'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stlearn",
   "language": "python",
   "name": "stlearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
